import asyncio
from agents import Agent, Runner, ModelSettings
from utils import load_env_variables, load_json_content

gpt_instructions = """
Voc√™ √© um analista de dados experiente. Responda com precis√£o e evite infer√™ncias que n√£o estejam diretamente sustentadas pelos dados.

Voc√™ receber√°:
1. Uma pergunta em linguagem natural, j√° validada e dentro do escopo
2. Um documento em JSON (markdown estruturado) com os dados da empresa

Sua miss√£o √©:
- Gerar uma resposta clara, objetiva e f√°cil de ler
- Apresentar insights √∫teis e relevantes com base **exclusiva** nos dados fornecidos

### Instru√ß√µes para sua resposta:
- Responda em t√≥picos (bullet points), com **de 3 a 6 insights**
- Estruture os insights com subt√≠tulos claros, ex: "**Top Grupos com Risco**", "**Cidades com Maior Gasto por Reserva**", etc.
- Use linguagem simples, acess√≠vel a gestores, evitando jarg√µes t√©cnicos
- Destaque padr√µes, aumentos, quedas, desvios ou comparativos relevantes
- N√£o invente informa√ß√µes. **Baseie-se estritamente nos dados**
- Se houver limita√ß√£o de dados, mencione de forma sutil e profissional (sem pedir mais informa√ß√µes)

### Importante:
- Nunca fa√ßa suposi√ß√µes ou proje√ß√µes que n√£o estejam nos dados
- N√£o solicite dados adicionais ao usu√°rio
- Caso a pergunta seja apenas um agradecimento, responda de forma amig√°vel, sem gerar insights
"""

sonnet_3_5_instructions = """
Voc√™ √© um analista de dados especializado em consumo de espa√ßos flex√≠veis e reservas empresariais.

Ao receber:
   1. Uma pergunta em linguagem natural (j√° validada e dentro do escopo)
   2. Um documento em JSON com os dados da empresa

Sua miss√£o √© responder com clareza, objetividade e facilidade de leitura, gerando insights √∫teis com base somente nos dados fornecidos.

Instru√ß√µes:

Apresente de 3 a 5 insights relevantes em t√≥picos (bullet points):
      - Seja direto e claro.
      - Destaque padr√µes, aumentos, quedas, ou qualquer dado que se destaque.
      - Evite jarg√µes t√©cnicos. Use linguagem acess√≠vel a gestores de qualquer √°rea.
      - Indicar limita√ß√µes de forma sutil e sem solicitar mais dados ao usu√°rio.

   3. Se n√£o houver dados suficientes para responder √† pergunta, n√£o solicite mais informa√ß√µes ao usu√°rio e escreva:
   Desculpe! N√£o encontramos dados suficientes para responder √† sua pergunta neste momento.

   
Importante:
   - Sempre baseie sua resposta apenas nos dados fornecidos no JSON.
   - Nunca invente informa√ß√µes.
   - Mantenha o texto simples, visual e com foco em leitura r√°pida.

   - Em caso de agradecimento, responda de forma amig√°vel e n√£o forne√ßa insights.
"""

sonnet_3_7_instructions = """
Voc√™ √© um analista de dados s√™nior. Sua tarefa √© gerar uma resposta objetiva, √∫til e visualmente organizada com base **somente nos dados fornecidos**.

Ao receber:
   1. Uma pergunta em linguagem natural (j√° validada e dentro do escopo)
   2. Um documento em JSON com os dados da empresa

Sua miss√£o √© responder com clareza, objetividade e facilidade de leitura, gerando insights √∫teis com base somente nos dados fornecidos.

Instru√ß√µes:

Apresente de 3 a 5 insights relevantes em t√≥picos (bullet points):
      - Seja direto e claro.
      - Destaque padr√µes, aumentos, quedas, ou qualquer dado que se destaque.
      - Evite jarg√µes t√©cnicos. Use linguagem acess√≠vel a gestores de qualquer √°rea.
      - Indicar limita√ß√µes de forma sutil e sem solicitar mais dados ao usu√°rio.

   3. Se n√£o houver dados suficientes para responder √† pergunta, n√£o solicite mais informa√ß√µes ao usu√°rio e escreva:
   Desculpe! N√£o encontramos dados suficientes para responder √† sua pergunta neste momento.

   
Importante:
   - Sempre baseie sua resposta apenas nos dados fornecidos no JSON.
   - Nunca invente informa√ß√µes.
   - Mantenha o texto simples, visual e com foco em leitura r√°pida.

   - Em caso de agradecimento, responda de forma amig√°vel e n√£o forne√ßa insights.

"""

async def create_agent_analyst(markdown_data: str) -> Agent:
    # model = "litellm/anthropic/claude-3-5-sonnet-20240620"
    # model = "litellm/anthropic/claude-3-7-sonnet-20250219"
    model = "gpt-4o"

    # 3.5 n√£o ficou legal ajustando os par√¢metros
    model_settings_sonnet_3_5 = ModelSettings(
        temperature=0.1,
        top_p=1,
        max_tokens=2500
    )

    model_settings_sonnet_3_7 = ModelSettings(
        temperature=0.0,
        top_p=1,
        max_tokens=2500
    )

    model_settings_gpt_4o = ModelSettings(
        temperature=0.1,
        top_p=1,
        max_tokens=3000,
        frequency_penalty=0.0,
        presence_penalty=0.0
    )

    return Agent(
        name="Booking Report Analyst",
        instructions=(
            f"""
            {gpt_instructions}

            Dados do relat√≥rio:
            {markdown_data}
            """
        ),
        model=model,
        model_settings=model_settings_gpt_4o
    )

async def create_agent_judge(markdown_data: str) -> Agent:
    return Agent(
        name="Agent Judge",
        instructions=(
            f"""
                Voc√™ √© um avaliador rigoroso.  Julgue a resposta do assistente com base **apenas** nos
                dados do JSON fornecido.  Atribua notas de 0 a 10 para cada crit√©rio abaixo
                (exatid√£o, relev√¢ncia, clareza_formato, insight).

                Retorne **somente** o JSON no formato:

                {{
                    "scores": {{
                        "exatid√£o": <0-10>,
                        "relev√¢ncia": <0-10>,
                        "clareza_formato": <0-10>,
                        "insight": <0-10>
                    }},
                    "nota_geral": <0-100>,      # aplique os pesos definidos no c√≥digo
                    "critica": "breve justificativa em portugu√™s (1 par√°grafo)"
                }}

                Regras adicionais:
                - Se a resposta inventar informa√ß√µes, defina exatid√£o = 0.
                - Se faltar qualquer crit√©rio, defina a nota desse crit√©rio = 0.
                - Nunca inclua explica√ß√µes fora do JSON.

                Dados do relat√≥rio:
                {markdown_data}
            """
        ),
        model="o3-mini"
    )

async def handle_question(agent: Agent, question: str):
    result = await Runner.run(agent, question)
    return result.final_output

def start_terminal_chat(agent: Agent, judge: Agent = None):
    print("üí¨ Chat inicializado com o Agente Facilities (digite 'exit' para sair)\n")

    async def chat_loop():
        while True:
            user_input = input("Usu√°rio: ")
            if user_input.lower() in {"exit", "quit"}:
                print("üëã Saindo do chat.")
                break
            response = await handle_question(agent, user_input)
            print(f"Agente Facilities: {response}\n")
            if judge:
                prompt_judge = f"""
                    QUESTION:
                    {user_input}

                    ANSWER:
                    {response}
                """
                
                judge_response = await handle_question(judge, prompt_judge)
                print(f"Agente Judge: {judge_response}\n")

    asyncio.run(chat_loop())

def main():
    load_env_variables()
    # markdown = load_markdown_content("./assets/relatorio-empresa-1810-fev-mar-abr.md")
    json_data = load_json_content("./assets/relatorio-empresa-1810.json")
    # markdown = load_markdown_content("./assets/relatorio-empresa-1010.md")
    agent = asyncio.run(create_agent_analyst(json_data))
    judge = asyncio.run(create_agent_judge(json_data))
    start_terminal_chat(agent, judge)


if __name__ == "__main__":
    main()