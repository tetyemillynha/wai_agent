import asyncio
from agents import (
    Agent,
    Runner,
    ModelSettings,
    GuardrailFunctionOutput,
    input_guardrail,
    output_guardrail,
    RunContextWrapper,
    TResponseInputItem,
    InputGuardrailTripwireTriggered,
    OutputGuardrailTripwireTriggered
)
from utils import load_env_variables, load_json_content
from fastapi.responses import JSONResponse

model_instructions = """
Voc√™ √© um analista de dados experiente especializado em consumo de espa√ßos flex√≠veis e reservas empresariais. Responda com precis√£o e evite infer√™ncias que n√£o estejam diretamente sustentadas pelos dados.

Voc√™ receber√°:
1. Uma pergunta em linguagem natural, j√° validada e dentro do escopo
2. Um documento em Markdown (markdown estruturado) com os dados da empresa

Sua miss√£o √©:
- Gerar uma resposta clara, objetiva e f√°cil de ler
- Apresentar insights √∫teis e relevantes com base **exclusiva** nos dados fornecidos

### Instru√ß√µes para sua resposta:
- Responda em t√≥picos (bullet points), com **de 3 a 6 insights**
- Estruture os insights com subt√≠tulos claros, ex: "**Top Grupos com Risco**", "**Cidades com Maior Gasto por Reserva**", etc.
- Use linguagem simples, acess√≠vel a gestores, evitando jarg√µes t√©cnicos
- Destaque padr√µes, aumentos, quedas, desvios ou comparativos relevantes
- N√£o invente informa√ß√µes. **Baseie-se estritamente nos dados**
- Se houver limita√ß√£o de dados, mencione de forma sutil e profissional (sem pedir mais informa√ß√µes)

### Importante:
- Nunca fa√ßa suposi√ß√µes ou proje√ß√µes que n√£o estejam nos dados
- N√£o solicite dados adicionais ao usu√°rio
- Caso a pergunta seja apenas um agradecimento, responda de forma amig√°vel, sem gerar insights
- Caso o Markdown esteja vazio responda: Hmm... essa eu ainda n√£o aprendi ou n√£o tenho dados suficientes para responder. ü§î
"""

async def create_agent_guardrail(name: str, instructions: str) -> Agent:
    return Agent(
        name=name,
        instructions=instructions,
        model="gpt-4o-mini",
    )

@input_guardrail
async def check_input_guardrail(
    ctx: RunContextWrapper[None],
    _: Agent,
    input: str | list[TResponseInputItem]
) -> GuardrailFunctionOutput:
    guardrail_agent = await create_agent_guardrail(
        name="Input Guardrail Agent",
        instructions=(
            """
            Voc√™ √© um classificador de escopo.  
            Sua tarefa √© classificar a pergunta do usu√°rio em **um √∫nico r√≥tulo**, com base no conte√∫do da pergunta.

            Responda **apenas com um destes r√≥tulos (sem nada mais)**:

            - `DENTRO_ESCOP` ‚Äî Se a pergunta estiver relacionada a reservas, consumo de cr√©ditos, espa√ßos, grupos, usu√°rios, cidades, produtos ou qualquer dado de uso da empresa em espa√ßos flex√≠veis.
            - `FORA_ESCOP` ‚Äî Se a pergunta for sobre outro assunto ou n√£o estiver relacionada ao uso de espa√ßos flex√≠veis.
            - `AGRADECIMENTO` ‚Äî Se for apenas uma sauda√ß√£o, agradecimento ou conversa informal (ex: "obrigado", "ol√°", "valeu", etc).

            ‚ö†Ô∏è N√£o justifique, n√£o explique. Responda apenas com um dos r√≥tulos acima.
            """
        )
    )
    result = await Runner.run(guardrail_agent, input, context=ctx.context)

    final_output = result.final_output.strip().upper()
    is_fail = final_output not in {"DENTRO_ESCOP", "AGRADECIMENTO"}

    print(f"üîç Input Guardrail Result: {final_output}")

    return GuardrailFunctionOutput(
        output_info=final_output,
        tripwire_triggered=is_fail
    )

@output_guardrail
async def check_output_guardrail(
    ctx: RunContextWrapper[None],
    _: Agent,
    response_agent: str
) -> GuardrailFunctionOutput:
    guardrail_agent = await create_agent_guardrail(
        name="Output Guardrail Classifier",
        instructions=(
            """
            Voc√™ √© um classificador de formato de resposta.

            Analise a sa√≠da do assistente e retorne **apenas um dos r√≥tulos abaixo**, conforme a situa√ß√£o:

            - `FORMATO_VALIDO` ‚Äî A resposta est√° em portugu√™s, tem de 3 a 6 t√≥picos com subt√≠tulos claros (ex: "**Cidades com Maior Gasto**"), e bullet points iniciados com "- " curtos, objetivos e acess√≠veis a gestores. Sem emojis, jarg√µes ou links.
            - `RESPOSTA_FALLBACK` ‚Äî A resposta √© exatamente: "Hmm... essa eu ainda n√£o aprendi ou n√£o tenho dados suficientes para responder. ü§î"
            - `SEM_SUBTITULO` ‚Äî Os insights est√£o apenas em bullet points, sem separa√ß√£o por subt√≠tulos.
            - `POUCOS_INSIGHTS` ‚Äî Menos de 3 insights ou t√≥picos.
            - `EXCESSO_INSIGHTS` ‚Äî Mais de 6 t√≥picos ou se√ß√µes.
            - `USO_EMOJI` ‚Äî A resposta cont√©m emojis.
            - `LINGUAGEM_TECNICA` ‚Äî A linguagem usada √© t√©cnica demais para um gestor comum.
            - `FORA_ESCOP` ‚Äî A resposta n√£o tem rela√ß√£o com reservas, consumo, espa√ßos ou dados da empresa.

            ‚ö†Ô∏è Responda apenas com o r√≥tulo. N√£o explique, n√£o formate.
            """
        )
    )

    result = await Runner.run(guardrail_agent, response_agent, context=ctx.context)

    final_output = result.final_output.strip().upper()
    tripwire = final_output not in {"FORMATO_VALIDO", "RESPOSTA_FALLBACK"}

    print(f"üìã Output Guardrail Result: {final_output}")

    return GuardrailFunctionOutput(
        output_info=final_output,
        tripwire_triggered=tripwire
    )


async def create_agent_analyst(json_data: str, user_question: str) -> Agent:
    # model = "litellm/anthropic/claude-3-5-sonnet-20240620"
    # model = "litellm/anthropic/claude-3-7-sonnet-20250219"
    model = "gpt-4o"

    # Gera relat√≥rio com base na pergunta real
    generate_agent = create_generate_report_agent(json_data, user_question)
    markdown_report = await handle_question(generate_agent, user_question)

    # print(f"üîç Relat√≥rio gerado: {markdown_report}")
    print(f"üîç Pergunta: {user_question}")

    # print(f"üîç Relat√≥rio gerado: {markdown_report}")
    
    model_settings_sonnet_3_5 = ModelSettings(
        temperature=0.1,
        top_p=1,
        max_tokens=2500
    )

    model_settings_sonnet_3_7 = ModelSettings(
        temperature=0.1,
        top_p=1,
        max_tokens=3000
    )

    model_settings_gpt_4o = ModelSettings(
        temperature=0.1,
        top_p=1,
        max_tokens=3000,
        frequency_penalty=0.0,
        presence_penalty=0.0
    )

    agent = Agent(
        name="Booking Report Analyst",
        instructions=(
            f"""
            {model_instructions}

            Dados do relat√≥rio:
            {markdown_report}
            """
        ),
        model=model,
        model_settings=model_settings_gpt_4o,
        input_guardrails=[check_input_guardrail],
        output_guardrails=[check_output_guardrail]
    )

    return agent, markdown_report

async def create_agent_judge(markdown_data: str) -> Agent:
    return Agent(
        name="Agent Judge",
        instructions=(
            f"""
                Voc√™ √© um avaliador rigoroso.  Julgue a resposta do assistente com base **apenas** nos
                dados do Markdown fornecido.  Atribua notas de 0 a 10 para cada crit√©rio abaixo
                (exatid√£o, relev√¢ncia, clareza_formato, insight).

                Retorne **somente** o Markdown no formato:

                {{
                    "scores": {{
                        "exatid√£o": <0-10>,
                        "relev√¢ncia": <0-10>,
                        "clareza_formato": <0-10>,
                        "insight": <0-10>
                    }},
                    "nota_geral": <0-100>,      # aplique os pesos definidos no c√≥digo
                    "critica": "breve justificativa em portugu√™s (1 par√°grafo)"
                }}

                Regras adicionais:
                - Se a resposta inventar informa√ß√µes, defina exatid√£o = 0.
                - Se faltar qualquer crit√©rio, defina a nota desse crit√©rio = 0.
                - Nunca inclua explica√ß√µes fora do Markdown.

                Dados do relat√≥rio:
                {markdown_data}
            """
        ),
        model="o3"
    )

async def handle_question(agent: Agent, question: str):
    result = await Runner.run(agent, question)
    return result.final_output



def start_terminal_chat(json_data: str):
    print("üí¨ Chat inicializado com o Agente Facilities (digite 'exit' para sair)\n")

    async def chat_loop():
        while True:
            user_input = input("Usu√°rio: ")
            if user_input.lower() in {"exit", "quit"}:
                print("üëã Saindo do chat.")
                break

            try:
                agent, markdown_report = await create_agent_analyst(json_data, user_input)

                response = await handle_question(agent, user_input)
                print(f"\nü§ñ Agente Facilities:\n{response}\n")

                judge = await create_agent_judge(markdown_report)

                if judge:
                    prompt_judge = f"""
                        QUESTION:
                        {user_input}

                        ANSWER:
                        {response}
                    """
                    judge_response = await handle_question(judge, prompt_judge)
                    print(f"üßë‚Äç‚öñÔ∏è Agente Judge:\n{judge_response}\n")

            except InputGuardrailTripwireTriggered:
                print("‚ùå Desculpe, sua pergunta est√° fora do escopo do assistente. Por favor, fa√ßa uma pergunta relacionada a:")
                print("- Consumo de cr√©ditos")
                print("- Reservas empresariais")
                print("- Uso de espa√ßos flex√≠veis")
                print("- Tend√™ncias por grupo, cidade ou usu√°rio")
                print("- Comparativos entre per√≠odos")
                print("- Informa√ß√µes baseadas em relat√≥rios de uso")
                print()
            except OutputGuardrailTripwireTriggered:
                print("Desculpe! Algo deu errado ao gerar a resposta.")
            

    asyncio.run(chat_loop())

def main():
    load_env_variables()
    json_data = load_json_content("./assets/relatorio-empresa-1810.json")
    
    start_terminal_chat(json_data)

def create_generate_report_agent(json_data: str, question: str):
    model = "gpt-4o"
    model_settings_gpt_4o = ModelSettings(
        temperature=0.1,
        top_p=1,
        max_tokens=3000,
        frequency_penalty=0.0,
        presence_penalty=0.0
    )

    generate_report_instructions = """
        Voc√™ √© um analista de dados experiente. Sua miss√£o √© gerar um relat√≥rio anal√≠tico **somente quando a pergunta estiver relacionada ao uso de cr√©ditos, reservas, espa√ßos, consumo ou an√°lise de comportamento dos usu√°rios**.

        Voc√™ recebeu a seguinte pergunta do usu√°rio:
        "{question}"

        ### Regras:
        - Se a pergunta for um agradecimento, cumprimento ou algo fora do contexto esperado, **n√£o gere nenhum relat√≥rio** e simplesmente retorne:
        > "{}"

        Com base apenas nos dados do JSON abaixo, gere um relat√≥rio completo com os principais insights que ajudam a responder a essa pergunta.

        Dados do relat√≥rio:
        {json_data}

        O relat√≥rio deve ser em **markdown bem formatado**, com se√ß√µes, listas e t√≠tulos claros, facil de ser lido e interpretado por outros analistas.
    """

    return Agent(
        name="Generate Report Agent",
        instructions=(
            f"""
            {generate_report_instructions}

            Dados do relat√≥rio:
            {json_data}
            """
        ),
        model=model,
        model_settings=model_settings_gpt_4o
    )


if __name__ == "__main__":
    main()