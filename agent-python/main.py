import asyncio
from agents import Agent, Runner
from pathlib import Path
from dotenv import load_dotenv
from llm_clients.openai_client import OpenAIClient
# from llm_clients.claude_client import ClaudeClient
# from llm_clients.llama_client import LLaMAClient
from summary_cache import get_summary_from_cache, save_summary_to_cache


def load_env_variables():
    load_dotenv()

def load_markdown_content(filepath: str) -> str:
    path = Path(filepath)
    if not path.exists():
        raise FileNotFoundError(f"File not found: {filepath}")
    return path.read_text(encoding="utf-8")

async def create_agent(markdown_data: str) -> Agent:
    # cached_summary = get_summary_from_cache(markdown_data)

    # if not cached_summary:
    #     print("üîÑ Gerando resumo...")
    #     summarizer = OpenAIClient(model="gpt-4o")
    #     summary = await summarizer.summarize(markdown_data)
    #     save_summary_to_cache(markdown_data, summary)
    # else:
    #     print("‚úÖ Resumo carregado do cache")
    #     summary = cached_summary

    #     with open("./assets/ultimo_resumo.md", "w", encoding="utf-8") as f:
    #         f.write(summary)


    client = OpenAIClient(model="gpt-4o")
    # client = ClaudeClient(model="claude-3-opus-20240229")
    # client = LLaMAClient(model="llama3.2")

    return Agent(
        name="Booking Report Analyst",
        instructions=(
            "Voc√™ √© um analista de dados especializado em consumo de espa√ßos flex√≠veis e reservas empresariais.\n\n"
            "Ao receber:\n"
            "1. Uma pergunta em linguagem natural (j√° validada e dentro do escopo)\n"
            "2. Um documento em Markdown com os dados da empresa\n\n"
            "Sua miss√£o √© responder com clareza, objetividade e facilidade de leitura, gerando insights √∫teis com base somente nos dados fornecidos.\n\n"
            "Instru√ß√µes:\n\n"
            "1. Comece com o t√≠tulo:\n"
            "üîç O que encontramos para voc√™\n\n"
            "2. Em seguida, apresente de 3 a 5 insights relevantes em t√≥picos (bullet points):\n"
            "   - Seja direto e claro.\n"
            "   - Destaque padr√µes, aumentos, quedas, ou qualquer dado que se destaque.\n"
            "   - Evite jarg√µes t√©cnicos. Use linguagem acess√≠vel a gestores de qualquer √°rea.\n\n"
            "3. Se n√£o houver dados suficientes para responder √† pergunta, escreva:\n"
            "Desculpe! N√£o encontramos dados suficientes para responder √† sua pergunta neste momento.\n\n"
            "Exemplo de resposta:\n\n"
            "---\n\n"
            "O que encontramos para voc√™\n\n"
            "- A empresa consumiu 2.130 cr√©ditos no per√≠odo analisado.\n"
            "- O espa√ßo mais utilizado foi a Sala Reuni√£o A, com 56% do total.\n"
            "- O grupo \"Comercial\" foi respons√°vel por 40% das reservas.\n"
            "- Houve uma queda de 18% no consumo em mar√ßo comparado a fevereiro.\n\n"
            "---\n\n"
            "Importante:\n"
            "- Sempre baseie sua resposta apenas nos dados fornecidos no Markdown.\n"
            "- Nunca invente informa√ß√µes.\n"
            "- Mantenha o texto simples, visual e com foco em leitura r√°pida.\n\n"
            "Dados do relat√≥rio:\n"
            f"{markdown_data}"
        ),
        model=client
    )

async def handle_question(agent: Agent, question: str):
    result = await Runner.run(agent, question)
    return result.final_output

def start_terminal_chat(agent: Agent):
    print("üí¨ Chat inicializado com o Agente Facilities (digite 'exit' para sair)\n")

    async def chat_loop():
        while True:
            user_input = input("Usu√°rio: ")
            if user_input.lower() in {"exit", "quit"}:
                print("üëã Saindo do chat.")
                break
            response = await handle_question(agent, user_input)
            print(f"Agente Facilities: {response}\n")

    asyncio.run(chat_loop())

def main():
    load_env_variables()
    markdown = load_markdown_content("./assets/relatorio-empresa-1810.md")
    agent = asyncio.run(create_agent(markdown))
    start_terminal_chat(agent)


if __name__ == "__main__":
    main()